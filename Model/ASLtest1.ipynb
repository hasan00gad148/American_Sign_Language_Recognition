{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe\n"
      ],
      "metadata": {
        "id": "irY8iAMK6iLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hvmo2aA6Z6h"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import time\n",
        "import json\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as tfl\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, BatchNormalization, ReLU, Dropout, GRU, ConvLSTM2D, Conv3D, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import random \n",
        "from sklearn.model_selection import train_test_split\n",
        "import mediapipe as mp\n",
        "import pickle as pk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6UN2MTUl6Z6m"
      },
      "outputs": [],
      "source": [
        "mp_holistic = mp.solutions.holistic # Holistic model\n",
        "mp_drawing = mp.solutions.drawing_utils # Drawing utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JyIC4AE6Z6n"
      },
      "outputs": [],
      "source": [
        "def mediapipe_detection(image, model):\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # COLOR CONVERSION BGR 2 RGB\n",
        "    image.flags.writeable = False                  # Image is no longer writeable\n",
        "    results = model.process(image)                 # Make prediction\n",
        "    image.flags.writeable = True                   # Image is now writeable \n",
        "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # COLOR COVERSION RGB 2 BGR\n",
        "    return  results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Llh8vNmy6Z6o"
      },
      "outputs": [],
      "source": [
        "def extract_keypoints(results):\n",
        "\n",
        "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*3)\n",
        "    lh = np.array([[res.x, res.y, res.z] for res in results.left_hand_landmarks.landmark]).flatten() if results.left_hand_landmarks else np.zeros(21*3)\n",
        "    rh = np.array([[res.x, res.y, res.z] for res in results.right_hand_landmarks.landmark]).flatten() if results.right_hand_landmarks else np.zeros(21*3)\n",
        "    return np.concatenate([pose, lh, rh])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZYCpm_F6Z6o"
      },
      "outputs": [],
      "source": [
        "def draw_styled_landmarks(image, results):\n",
        "    # Draw face connections\n",
        "    mp_drawing.draw_landmarks(image, results.face_landmarks, mp_holistic.FACEMESH_TESSELATION, \n",
        "                             mp_drawing.DrawingSpec(color=(80,110,10), thickness=1, circle_radius=1), \n",
        "                             mp_drawing.DrawingSpec(color=(80,256,121), thickness=1, circle_radius=1)\n",
        "                             ) \n",
        "    # Draw pose connections\n",
        "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_holistic.POSE_CONNECTIONS,\n",
        "                             mp_drawing.DrawingSpec(color=(80,22,10), thickness=2, circle_radius=4), \n",
        "                             mp_drawing.DrawingSpec(color=(80,44,121), thickness=2, circle_radius=2)\n",
        "                             ) \n",
        "    # Draw left hand connections\n",
        "    mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
        "                             mp_drawing.DrawingSpec(color=(121,22,76), thickness=2, circle_radius=4), \n",
        "                             mp_drawing.DrawingSpec(color=(121,44,250), thickness=2, circle_radius=2)\n",
        "                             ) \n",
        "    # Draw right hand connections  \n",
        "    mp_drawing.draw_landmarks(image, results.right_hand_landmarks, mp_holistic.HAND_CONNECTIONS, \n",
        "                             mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=4), \n",
        "                             mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
        "                             ) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4TDRykUC6Z6q"
      },
      "outputs": [],
      "source": [
        "holistic = mp_holistic.Holistic(min_detection_confidence=0.25, min_tracking_confidence=0.25) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-aKarXd6Z6r"
      },
      "outputs": [],
      "source": [
        "def videoProc(path):\n",
        "    \"###\"\n",
        "    cap = cv2.VideoCapture(path)\n",
        "    success, frame = cap.read()\n",
        "    \n",
        "    fno = 0\n",
        "    framecount = 20\n",
        "    fps = round(cap.get(cv2.CAP_PROP_FPS), 0) \n",
        "    \n",
        "    v = []\n",
        "    \n",
        "\n",
        "\n",
        "    while True:\n",
        "        success, frame = cap.read()\n",
        "        if fno >=framecount:\n",
        "            break \n",
        "        \n",
        "     \n",
        "\n",
        "        if success:\n",
        "            frame = cv2.resize(frame, (720,480), interpolation = cv2.INTER_AREA)\n",
        "            results = mediapipe_detection(frame, holistic)\n",
        "            eres = extract_keypoints(results)\n",
        "\n",
        "            tmp=  np.reshape(eres, (1,258))\n",
        "            v.append(tmp)\n",
        "            \n",
        "            # draw_styled_landmarks(frame, results)\n",
        "            # plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
        "            # plt.show()\n",
        "            fno += 1\n",
        "        else:\n",
        "            break\n",
        "\n",
        "# if cv2.waitKey(1) & 0xFF == ord('q') or ret==False :\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    \n",
        "    f = len(v)\n",
        "    v = np.array(v) if f >0 else[]\n",
        "    v =np.reshape(v,(f,225))if f >0 else[]\n",
        "   \n",
        "\n",
        "\n",
        "    if f>0:      \n",
        "        m = v.mean(axis=-1)     \n",
        "        tmpv = v.T \n",
        "        tmpv -=  m\n",
        "        v = tmpv.T\n",
        "        m = v.mean(axis=0) \n",
        "        v -= m\n",
        "    if fno<framecount and fno>0:\n",
        "        tmp = np.zeros((framecount-fno,225))\n",
        "        v = np.concatenate((v, tmp), axis=0) \n",
        "\n",
        "    return v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IfFD2qAP6Z6s"
      },
      "outputs": [],
      "source": [
        "v = videoProc(\"./testdata/z20.mp4\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3oL2pf_6Z6s"
      },
      "outputs": [],
      "source": [
        "v[17].min(),v[17].max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Gp0cvjZ6Z6t"
      },
      "outputs": [],
      "source": [
        "reconstructed_model = tf.keras.models.load_model(\"./modelAsl/v3\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YtnWiim6Z6t"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thBztgmb6Z6t"
      },
      "outputs": [],
      "source": [
        "p = model.predict_step(np.reshape(v, (1,20,258)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQlR7yV86Z6u"
      },
      "outputs": [],
      "source": [
        "np.argmax(p),p"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.10.2 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "26cdd06f4768c01aff35b8a9e3baf997ace62fbda00b5d467f0db2807f78448e"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}